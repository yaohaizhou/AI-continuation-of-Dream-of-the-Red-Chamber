#!/usr/bin/env python3
"""
AIç»­å†™çº¢æ¥¼æ¢¦ - ä¸»ç¨‹åºå…¥å£
åŸºäºLangChainçš„çº¢æ¥¼æ¢¦ç»­å†™ç³»ç»Ÿ
"""

import asyncio
import sys
from pathlib import Path
from typing import Optional

import click
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from loguru import logger

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from ai_hongloumeng import HongLouMengContinuation, Config
from ai_hongloumeng.utils import FileManager
from ai_hongloumeng.prompts import PromptTemplates
from data_processing import HongLouMengDataPipeline
from knowledge_enhancement import EnhancedPrompter, TaixuProphecyExtractor, FateConsistencyChecker
from rag_retrieval import RAGPipeline, create_rag_pipeline

# åˆå§‹åŒ–æ§åˆ¶å°
console = Console()

# é…ç½®æ—¥å¿—
logger.remove()  # ç§»é™¤é»˜è®¤çš„æ—¥å¿—å¤„ç†å™¨
logger.add(
    "logs/app.log",
    rotation="10 MB",
    retention="7 days",
    level="INFO",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
)
logger.add(
    sys.stderr,
    level="INFO",
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | {message}"
)


@click.group()
@click.version_option(version="1.0.0")
def cli():
    """AIç»­å†™çº¢æ¥¼æ¢¦ - åŸºäºLangChainçš„æ™ºèƒ½ç»­å†™ç³»ç»Ÿ"""
    console.print(Panel.fit(
        "[bold red]AIç»­å†™çº¢æ¥¼æ¢¦[/bold red]\n"
        "[dim]åŸºäºLangChainçš„çº¢æ¥¼æ¢¦æ™ºèƒ½ç»­å†™ç³»ç»Ÿ[/dim]",
        border_style="red"
    ))


@cli.command()
@click.option('--context-file', '-f', type=click.Path(exists=True), help='åŒ…å«ä¸Šä¸‹æ–‡çš„æ–‡ä»¶è·¯å¾„')
@click.option('--context', '-c', type=str, help='ç›´æ¥è¾“å…¥çš„ä¸Šä¸‹æ–‡æ–‡æœ¬')
@click.option('--type', '-t', 
              type=click.Choice(['basic', 'dialogue', 'scene', 'poetry']), 
              default='basic', help='ç»­å†™ç±»å‹')
@click.option('--length', '-l', type=int, default=800, help='ç»­å†™æœ€å¤§é•¿åº¦')
@click.option('--output', '-o', type=str, help='è¾“å‡ºæ–‡ä»¶å')
@click.option('--model', '-m', type=str, default='gpt-4', help='ä½¿ç”¨çš„æ¨¡å‹')
@click.option('--temperature', type=float, default=0.8, help='æ¨¡å‹æ¸©åº¦å‚æ•°')
def continue_story(context_file, context, type, length, output, model, temperature):
    """ç»­å†™çº¢æ¥¼æ¢¦æ•…äº‹"""
    asyncio.run(_continue_story_async(
        context_file, context, type, length, output, model, temperature
    ))


async def _continue_story_async(context_file, context, type, length, output, model, temperature):
    """å¼‚æ­¥ç»­å†™æ•…äº‹"""
    try:
        # è·å–ä¸Šä¸‹æ–‡
        if context_file:
            file_manager = FileManager()
            context = file_manager.read_text_file(Path(context_file))
            console.print(f"[green]ä»æ–‡ä»¶åŠ è½½ä¸Šä¸‹æ–‡: {context_file}[/green]")
        elif not context:
            console.print("[red]é”™è¯¯: è¯·æä¾›ä¸Šä¸‹æ–‡æ–‡æœ¬æˆ–æ–‡ä»¶[/red]")
            return
        
        # åˆ›å»ºé…ç½®
        config = Config()
        config.model.model_name = model
        config.model.temperature = temperature
        config.writing.max_continuation_length = length
        
        # åˆå§‹åŒ–ç»­å†™ç³»ç»Ÿ
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("åˆå§‹åŒ–AIç»­å†™ç³»ç»Ÿ...", total=None)
            continuation_system = HongLouMengContinuation(config)
            progress.update(task, description="ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
        # æ˜¾ç¤ºä¸Šä¸‹æ–‡é¢„è§ˆ
        context_preview = context[:200] + "..." if len(context) > 200 else context
        console.print(Panel(
            f"[bold]ä¸Šä¸‹æ–‡é¢„è§ˆ:[/bold]\n{context_preview}",
            title="è¾“å…¥æ–‡æœ¬",
            border_style="blue"
        ))
        
        # è¿›è¡Œç»­å†™
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("AIç»­å†™ä¸­...", total=None)
            
            # æ ¹æ®ç±»å‹è®¾ç½®å‚æ•°
            kwargs = {}
            if type == "dialogue":
                kwargs = {
                    "character_info": "çº¢æ¥¼æ¢¦ä¸»è¦äººç‰©",
                    "scene_context": "å¤§è§‚å›­æ—¥å¸¸",
                    "dialogue_context": "äººç‰©å¯¹è¯"
                }
            elif type == "scene":
                kwargs = {
                    "scene_setting": "å¤§è§‚å›­åœºæ™¯",
                    "time": "æ˜¥æ—¥åˆå",
                    "location": "å¤§è§‚å›­",
                    "characters": "ä¸»è¦äººç‰©"
                }
            elif type == "poetry":
                kwargs = {
                    "poetry_type": "å¾‹è¯—",
                    "theme": "æ˜¥æ—¥æ„Ÿæ€€",
                    "character": "å®ç‰"
                }
            
            result = await continuation_system.continue_story(
                context=context,
                continuation_type=type,
                max_length=length,
                **kwargs
            )
            
            progress.update(task, description="ç»­å†™å®Œæˆ")
        
        # æ˜¾ç¤ºç»“æœ
        console.print(Panel(
            result["continuation"],
            title=f"[bold green]AIç»­å†™ç»“æœ ({type})[/bold green]",
            border_style="green"
        ))
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        metadata = result["metadata"]
        stats_text = f"""
[bold]ç”Ÿæˆç»Ÿè®¡:[/bold]
â€¢ æ¨¡å‹: {metadata['model']}
â€¢ æ¸©åº¦: {metadata.get('temperature', 'N/A')}
â€¢ ä½¿ç”¨Token: {metadata.get('tokens_used', 'N/A')}
â€¢ æˆæœ¬: ${metadata.get('cost', 0):.6f}
â€¢ ç»­å†™å­—æ•°: {len(result['continuation'])}å­—
        """
        console.print(Panel(stats_text.strip(), title="ç»Ÿè®¡ä¿¡æ¯", border_style="yellow"))
        
        # è´¨é‡æ£€æŸ¥
        quality = result.get("quality_check", {})
        if not quality.get("is_valid", True):
            console.print(Panel(
                f"[red]è´¨é‡è­¦å‘Š:[/red]\n" + "\n".join(f"â€¢ {issue}" for issue in quality.get("issues", [])),
                title="è´¨é‡æ£€æŸ¥",
                border_style="red"
            ))
        
        # ä¿å­˜ç»“æœ
        if output or click.confirm("æ˜¯å¦ä¿å­˜ç»“æœåˆ°æ–‡ä»¶?"):
            output_path = continuation_system.save_continuation(result, output)
            console.print(f"[green]ç»“æœå·²ä¿å­˜åˆ°: {output_path}[/green]")
            
    except Exception as e:
        console.print(f"[red]ç»­å†™å¤±è´¥: {e}[/red]")
        logger.error(f"ç»­å†™å¤±è´¥: {e}")


@cli.command()
@click.option('--input-dir', '-i', type=click.Path(exists=True), required=True, help='è¾“å…¥æ–‡ä»¶ç›®å½•')
@click.option('--output-dir', '-o', type=click.Path(), help='è¾“å‡ºç›®å½•')
@click.option('--type', '-t', 
              type=click.Choice(['basic', 'dialogue', 'scene', 'poetry']), 
              default='basic', help='ç»­å†™ç±»å‹')
@click.option('--length', '-l', type=int, default=800, help='ç»­å†™æœ€å¤§é•¿åº¦')
def batch_continue(input_dir, output_dir, type, length):
    """æ‰¹é‡ç»­å†™å¤šä¸ªæ–‡æœ¬æ–‡ä»¶"""
    asyncio.run(_batch_continue_async(input_dir, output_dir, type, length))


async def _batch_continue_async(input_dir, output_dir, type, length):
    """å¼‚æ­¥æ‰¹é‡ç»­å†™"""
    try:
        input_path = Path(input_dir)
        output_path = Path(output_dir) if output_dir else Path("output")
        
        # æŸ¥æ‰¾æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶
        text_files = list(input_path.glob("*.txt"))
        if not text_files:
            console.print("[red]åœ¨è¾“å…¥ç›®å½•ä¸­æœªæ‰¾åˆ°.txtæ–‡ä»¶[/red]")
            return
        
        console.print(f"[green]æ‰¾åˆ°{len(text_files)}ä¸ªæ–‡æœ¬æ–‡ä»¶[/green]")
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        continuation_system = HongLouMengContinuation()
        file_manager = FileManager()
        
        # è¯»å–æ‰€æœ‰æ–‡ä»¶å†…å®¹
        contexts = []
        for file_path in text_files:
            content = file_manager.read_text_file(file_path)
            contexts.append(content)
        
        # æ‰¹é‡ç»­å†™
        with Progress(console=console) as progress:
            task = progress.add_task("æ‰¹é‡ç»­å†™ä¸­...", total=len(contexts))
            
            results = await continuation_system.batch_continuation(
                contexts=contexts,
                continuation_type=type,
                max_length=length
            )
            
            progress.update(task, completed=len(contexts))
        
        # ä¿å­˜ç»“æœ
        output_path.mkdir(exist_ok=True)
        successful_count = 0
        
        for i, (result, file_path) in enumerate(zip(results, text_files)):
            if "error" not in result:
                output_filename = f"{file_path.stem}_continued.txt"
                output_file_path = output_path / output_filename
                
                formatted_output = continuation_system.output_formatter.format_continuation_output(
                    original_text=result["context"],
                    continuation=result["continuation"],
                    metadata=result["metadata"]
                )
                
                file_manager.write_text_file(output_file_path, formatted_output)
                successful_count += 1
                
        console.print(f"[green]æ‰¹é‡ç»­å†™å®Œæˆ! æˆåŠŸå¤„ç†{successful_count}/{len(text_files)}ä¸ªæ–‡ä»¶[/green]")
        console.print(f"[green]ç»“æœä¿å­˜åœ¨: {output_path}[/green]")
        
    except Exception as e:
        console.print(f"[red]æ‰¹é‡ç»­å†™å¤±è´¥: {e}[/red]")
        logger.error(f"æ‰¹é‡ç»­å†™å¤±è´¥: {e}")


@cli.command()
@click.option('--text', '-t', type=str, required=True, help='è¦åˆ†æçš„æ–‡æœ¬')
def analyze(text):
    """åˆ†ææ–‡æœ¬ä¸­çš„çº¢æ¥¼æ¢¦å…ƒç´ """
    try:
        continuation_system = HongLouMengContinuation()
        analysis = continuation_system.get_character_analysis(text)
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        result_text = f"""
[bold]æ–‡æœ¬åˆ†æç»“æœ:[/bold]

[bold blue]äººç‰©:[/bold blue]
{', '.join(analysis['characters']) if analysis['characters'] else 'æœªè¯†åˆ«åˆ°çº¢æ¥¼æ¢¦äººç‰©'}

[bold blue]åœ°ç‚¹:[/bold blue]
{', '.join(analysis['locations']) if analysis['locations'] else 'æœªè¯†åˆ«åˆ°çº¢æ¥¼æ¢¦åœ°ç‚¹'}

[bold blue]å¯¹è¯æ•°é‡:[/bold blue]
{len(analysis['dialogues'])}æ®µå¯¹è¯

[bold blue]å­—æ•°ç»Ÿè®¡:[/bold blue]
{analysis['word_count']}å­—
        """
        
        console.print(Panel(result_text.strip(), title="æ–‡æœ¬åˆ†æ", border_style="cyan"))
        
        # æ˜¾ç¤ºå¯¹è¯è¯¦æƒ…
        if analysis['dialogues']:
            dialogue_text = "\n".join([
                f"{i+1}. {dialogue['content'][:50]}..." 
                for i, dialogue in enumerate(analysis['dialogues'][:5])
            ])
            console.print(Panel(dialogue_text, title="å¯¹è¯é¢„è§ˆ (å‰5æ®µ)", border_style="magenta"))
            
    except Exception as e:
        console.print(f"[red]åˆ†æå¤±è´¥: {e}[/red]")
        logger.error(f"åˆ†æå¤±è´¥: {e}")


@cli.command()
def setup():
    """åˆå§‹åŒ–é¡¹ç›®è®¾ç½®"""
    try:
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        directories = ["data", "output", "config", "logs"]
        for dir_name in directories:
            Path(dir_name).mkdir(exist_ok=True)
            console.print(f"[green]âœ“[/green] åˆ›å»ºç›®å½•: {dir_name}")
        
        # åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶
        config = Config()
        console.print(f"[green]âœ“[/green] åˆ›å»ºé…ç½®æ–‡ä»¶: {config.config_path}")
        
        # åˆ›å»ºç¤ºä¾‹ç¯å¢ƒå˜é‡æ–‡ä»¶
        env_content = """# OpenAI APIé…ç½®
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1

# å¯é€‰ï¼šå¦‚æœä½¿ç”¨å…¶ä»–å…¼å®¹çš„APIæœåŠ¡
# OPENAI_BASE_URL=https://your-custom-api-endpoint.com/v1
"""
        
        env_path = Path(".env")
        if not env_path.exists():
            with open(env_path, 'w', encoding='utf-8') as f:
                f.write(env_content)
            console.print(f"[green]âœ“[/green] åˆ›å»ºç¯å¢ƒå˜é‡æ–‡ä»¶: .env")
        else:
            console.print(f"[yellow]![/yellow] ç¯å¢ƒå˜é‡æ–‡ä»¶å·²å­˜åœ¨: .env")
        
        console.print(Panel(
            "[bold green]é¡¹ç›®åˆå§‹åŒ–å®Œæˆ![/bold green]\n\n"
            "[bold]ä¸‹ä¸€æ­¥:[/bold]\n"
            "1. ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„ OpenAI API Key\n"
            "2. (å¯é€‰) å°†çº¢æ¥¼æ¢¦åŸæ–‡æ”¾å…¥ data/original_hongloumeng.txt\n"
            "3. è¿è¡Œ: python main.py continue-story --help æŸ¥çœ‹ä½¿ç”¨æ–¹æ³•",
            title="è®¾ç½®å®Œæˆ",
            border_style="green"
        ))
        
    except Exception as e:
        console.print(f"[red]åˆå§‹åŒ–å¤±è´¥: {e}[/red]")
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")


@cli.command()
@click.option('--input-file', '-i', type=click.Path(exists=True), required=True, 
              help='çº¢æ¥¼æ¢¦åŸæ–‡æ–‡ä»¶è·¯å¾„')
@click.option('--output-dir', '-o', type=click.Path(), default='data/processed', 
              help='è¾“å‡ºç›®å½•è·¯å¾„')
@click.option('--dict-path', '-d', type=click.Path(), 
              help='è‡ªå®šä¹‰è¯å…¸è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
@click.option('--skip-tokenization', is_flag=True, 
              help='è·³è¿‡åˆ†è¯å¤„ç†')
@click.option('--skip-entity-recognition', is_flag=True, 
              help='è·³è¿‡å®ä½“è¯†åˆ«')
@click.option('--force', is_flag=True, 
              help='å¼ºåˆ¶é‡æ–°å¤„ç†ï¼ˆå³ä½¿è¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼‰')
def process_data(input_file, output_dir, dict_path, skip_tokenization, skip_entity_recognition, force):
    """å®Œæ•´å¤„ç†çº¢æ¥¼æ¢¦æ–‡æœ¬æ•°æ®ï¼šé¢„å¤„ç†ã€åˆ†è¯ã€å®ä½“è¯†åˆ«"""
    try:
        console.print(Panel.fit(
            "[bold blue]å¼€å§‹çº¢æ¥¼æ¢¦æ•°æ®å¤„ç†[/bold blue]",
            border_style="blue"
        ))
        
        # åˆå§‹åŒ–æ•°æ®å¤„ç†ç®¡é“
        pipeline = HongLouMengDataPipeline(
            custom_dict_path=dict_path,
            output_base_dir=output_dir
        )
        
        # æ˜¾ç¤ºç®¡é“ä¿¡æ¯
        pipeline_info = pipeline.get_pipeline_info()
        console.print(f"[green]è¾“å‡ºç›®å½•: {pipeline_info['output_base_dir']}[/green]")
        if dict_path:
            console.print(f"[green]è‡ªå®šä¹‰è¯å…¸: {dict_path}[/green]")
        
        # å¼€å§‹å¤„ç†
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("æ•°æ®å¤„ç†ä¸­...", total=None)
            
            result = pipeline.process_complete_text(
                input_file=input_file,
                include_tokenization=not skip_tokenization,
                include_entity_recognition=not skip_entity_recognition,
                force_reprocess=force
            )
            
            progress.update(task, description="æ•°æ®å¤„ç†å®Œæˆ")
        
        # æ˜¾ç¤ºå¤„ç†ç»“æœ
        if 'error' in result:
            console.print(f"[red]å¤„ç†å¤±è´¥: {result['error']}[/red]")
            return
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats_text = "[bold]å¤„ç†ç»Ÿè®¡:[/bold]\n"
        
        if 'preprocessing' in result['statistics']:
            stats = result['statistics']['preprocessing']
            stats_text += f"â€¢ æ€»å­—ç¬¦æ•°: {stats['total_chars']:,}\n"
            stats_text += f"â€¢ æ®µè½æ•°: {stats['total_paragraphs']:,}\n"
            stats_text += f"â€¢ å¯¹è¯æ•°: {stats['total_dialogues']:,}\n"
        
        if 'chapters' in result['statistics']:
            stats = result['statistics']['chapters']
            stats_text += f"â€¢ ç« èŠ‚æ•°: {stats['total_chapters']}\n"
        
        if 'tokenization' in result['statistics']:
            stats = result['statistics']['tokenization']
            stats_text += f"â€¢ æ€»è¯æ•°: {stats['total_words']:,}\n"
            stats_text += f"â€¢ ç‹¬ç‰¹è¯æ±‡: {stats['unique_words']:,}\n"
            stats_text += f"â€¢ è‡ªå®šä¹‰è¯æ±‡: {stats['custom_words_found']}\n"
        
        console.print(Panel(stats_text.strip(), title="å¤„ç†ç»Ÿè®¡", border_style="green"))
        
        # æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶
        files_text = "[bold]ç”Ÿæˆçš„æ–‡ä»¶:[/bold]\n"
        for file_type, file_path in result['output_files'].items():
            files_text += f"â€¢ {file_type}: {file_path}\n"
        
        console.print(Panel(files_text.strip(), title="è¾“å‡ºæ–‡ä»¶", border_style="yellow"))
        
        console.print("[green]âœ“ æ•°æ®å¤„ç†å®Œæˆï¼[/green]")
        
    except Exception as e:
        console.print(f"[red]æ•°æ®å¤„ç†å¤±è´¥: {e}[/red]")
        logger.error(f"æ•°æ®å¤„ç†å¤±è´¥: {e}")


@cli.command()
@click.option('--input-file', '-i', type=click.Path(exists=True), required=True,
              help='è¦åˆ†è¯çš„æ–‡æœ¬æ–‡ä»¶')
@click.option('--output-file', '-o', type=click.Path(),
              help='åˆ†è¯ç»“æœè¾“å‡ºæ–‡ä»¶')
@click.option('--dict-path', '-d', type=click.Path(),
              help='è‡ªå®šä¹‰è¯å…¸è·¯å¾„')
@click.option('--mode', '-m', type=click.Choice(['default', 'search', 'all']),
              default='default', help='åˆ†è¯æ¨¡å¼')
def tokenize(input_file, output_file, dict_path, mode):
    """å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯å¤„ç†"""
    try:
        from data_processing import HongLouMengTokenizer
        
        console.print(Panel.fit(
            f"[bold cyan]æ–‡æœ¬åˆ†è¯å¤„ç†[/bold cyan]\næ¨¡å¼: {mode}",
            border_style="cyan"
        ))
        
        # åˆå§‹åŒ–åˆ†è¯å™¨
        tokenizer = HongLouMengTokenizer(dict_path)
        
        # å¤„ç†æ–‡ä»¶
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("åˆ†è¯å¤„ç†ä¸­...", total=None)
            
            result = tokenizer.tokenize_file(input_file, output_file)
            
            progress.update(task, description="åˆ†è¯å¤„ç†å®Œæˆ")
        
        # æ˜¾ç¤ºç»“æœ
        analysis = result['analysis']
        
        stats_text = f"""[bold]åˆ†è¯ç»Ÿè®¡:[/bold]
â€¢ æ€»è¯æ•°: {analysis['word_count']:,}
â€¢ ç‹¬ç‰¹è¯æ±‡: {analysis['unique_words']:,}
â€¢ è‡ªå®šä¹‰è¯æ±‡å‘ç°: {len(analysis['custom_words_found'])}
â€¢ äººç‰©å®ä½“: {len(analysis['entities']['persons'])}
â€¢ åœ°ç‚¹å®ä½“: {len(analysis['entities']['locations'])}
â€¢ å¯¹è±¡å®ä½“: {len(analysis['entities']['objects'])}
"""
        
        console.print(Panel(stats_text.strip(), title="åˆ†è¯ç»“æœ", border_style="green"))
        console.print(f"[green]åˆ†è¯ç»“æœå·²ä¿å­˜åˆ°: {result['output_file']}[/green]")
        
    except Exception as e:
        console.print(f"[red]åˆ†è¯å¤„ç†å¤±è´¥: {e}[/red]")
        logger.error(f"åˆ†è¯å¤„ç†å¤±è´¥: {e}")


@cli.command()
@click.option('--input-file', '-i', type=click.Path(exists=True), required=True,
              help='è¦è¿›è¡Œå®ä½“è¯†åˆ«çš„æ–‡æœ¬æ–‡ä»¶')
@click.option('--output-file', '-o', type=click.Path(),
              help='å®ä½“è¯†åˆ«ç»“æœè¾“å‡ºæ–‡ä»¶')
@click.option('--dict-path', '-d', type=click.Path(),
              help='è‡ªå®šä¹‰è¯å…¸è·¯å¾„')
def recognize_entities(input_file, output_file, dict_path):
    """å¯¹æ–‡æœ¬è¿›è¡Œå®ä½“è¯†åˆ«"""
    try:
        from data_processing import EntityRecognizer
        
        console.print(Panel.fit(
            "[bold magenta]å®ä½“è¯†åˆ«å¤„ç†[/bold magenta]",
            border_style="magenta"
        ))
        
        # åˆå§‹åŒ–å®ä½“è¯†åˆ«å™¨
        recognizer = EntityRecognizer(dict_path)
        
        # è¯»å–æ–‡ä»¶
        with open(input_file, 'r', encoding='utf-8') as f:
            text = f.read()
        
        # å¤„ç†å®ä½“è¯†åˆ«
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("å®ä½“è¯†åˆ«ä¸­...", total=None)
            
            entities = recognizer.recognize_entities(text)
            stats = recognizer.get_entity_statistics(text)
            
            progress.update(task, description="å®ä½“è¯†åˆ«å®Œæˆ")
        
        # ä¿å­˜ç»“æœ
        if output_file:
            recognizer.export_entities(text, output_file)
        
        # æ˜¾ç¤ºç»“æœ
        stats_text = f"""[bold]å®ä½“è¯†åˆ«ç»Ÿè®¡:[/bold]
â€¢ äººç‰©: {stats['entity_counts']['persons']}ä¸ª
â€¢ åœ°ç‚¹: {stats['entity_counts']['locations']}ä¸ª
â€¢ ç‰©å“: {stats['entity_counts']['objects']}ä¸ª
â€¢ å¯¹è¯: {stats['entity_counts']['dialogues']}æ®µ
â€¢ ç§°è°“: {stats['entity_counts']['titles']}ä¸ª

[bold]å®ä½“å¯†åº¦ï¼ˆæ¯åƒå­—ï¼‰:[/bold]
â€¢ äººç‰©: {stats['entity_density']['persons']}
â€¢ åœ°ç‚¹: {stats['entity_density']['locations']}
"""
        
        console.print(Panel(stats_text.strip(), title="å®ä½“è¯†åˆ«ç»“æœ", border_style="green"))
        
        if output_file:
            console.print(f"[green]å®ä½“è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: {output_file}[/green]")
        
    except Exception as e:
        console.print(f"[red]å®ä½“è¯†åˆ«å¤±è´¥: {e}[/red]")
        logger.error(f"å®ä½“è¯†åˆ«å¤±è´¥: {e}")


@cli.command()
@click.option('--chapters-dir', '-d', type=click.Path(exists=True),
              default='data/processed/chapters', help='ç« èŠ‚æ–‡ä»¶ç›®å½•')
def batch_process_chapters(chapters_dir):
    """æ‰¹é‡å¤„ç†æ‰€æœ‰ç« èŠ‚æ–‡ä»¶"""
    try:
        from data_processing import HongLouMengDataPipeline
        
        console.print(Panel.fit(
            "[bold yellow]æ‰¹é‡å¤„ç†ç« èŠ‚[/bold yellow]",
            border_style="yellow"
        ))
        
        # åˆå§‹åŒ–ç®¡é“
        pipeline = HongLouMengDataPipeline()
        
        # æ‰¹é‡å¤„ç†
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("æ‰¹é‡å¤„ç†ç« èŠ‚ä¸­...", total=None)
            
            results = pipeline.batch_process_chapters()
            
            progress.update(task, description="æ‰¹é‡å¤„ç†å®Œæˆ")
        
        # æ˜¾ç¤ºç»“æœ
        success_count = len([r for r in results if 'error' not in r])
        total_count = len(results)
        
        console.print(f"[green]æ‰¹é‡å¤„ç†å®Œæˆ: {success_count}/{total_count} ä¸ªç« èŠ‚å¤„ç†æˆåŠŸ[/green]")
        
        if success_count < total_count:
            error_count = total_count - success_count
            console.print(f"[yellow]è­¦å‘Š: {error_count} ä¸ªç« èŠ‚å¤„ç†å¤±è´¥[/yellow]")
        
    except Exception as e:
        console.print(f"[red]æ‰¹é‡å¤„ç†å¤±è´¥: {e}[/red]")
        logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")


@cli.command()
@click.option('--context', '-c', required=True, help='ç»­å†™çš„ä¸Šä¸‹æ–‡')
@click.option('--prompt-type', '-t', type=click.Choice(['basic', 'dialogue', 'scene', 'poetry']),
              default='basic', help='æç¤ºè¯ç±»å‹')
@click.option('--max-length', '-l', type=int, default=500, help='ç»­å†™é•¿åº¦')
@click.option('--traditional', is_flag=True, help='ä½¿ç”¨ä¼ ç»Ÿæç¤ºè¯ï¼ˆä¸ä½¿ç”¨çŸ¥è¯†å¢å¼ºï¼‰')
def enhanced_continue(context, prompt_type, max_length, traditional):
    """ä½¿ç”¨çŸ¥è¯†å¢å¼ºåŠŸèƒ½è¿›è¡Œç»­å†™æ¼”ç¤º"""
    console.print(Panel.fit(
        f"[bold green]çŸ¥è¯†å¢å¼ºç»­å†™æ¼”ç¤º[/bold green]\n"
        f"ä¸Šä¸‹æ–‡: {context}\n"
        f"ç±»å‹: {prompt_type}\n"
        f"é•¿åº¦: {max_length}å­—\n"
        f"æ¨¡å¼: {'ä¼ ç»Ÿ' if traditional else 'çŸ¥è¯†å¢å¼º'}",
        title="ğŸŒŸ çŸ¥è¯†å¢å¼ºç»­å†™"
    ))
    
    try:
        # åˆå§‹åŒ–æç¤ºè¯æ¨¡æ¿
        prompt_templates = PromptTemplates(enable_knowledge_enhancement=not traditional)
        
        if traditional:
            console.print("[yellow]ä½¿ç”¨ä¼ ç»Ÿæç¤ºè¯æ¨¡å¼[/yellow]")
        else:
            console.print("[green]ä½¿ç”¨çŸ¥è¯†å¢å¼ºæ¨¡å¼[/green]")
            
        # è·å–å†™ä½œå»ºè®®
        suggestions = prompt_templates.get_writing_suggestions(context)
        
        if suggestions['knowledge_enhanced']:
            console.print("\nğŸ“Š çŸ¥è¯†åˆ†æç»“æœ:")
            console.print(f"  è¯†åˆ«äººç‰©: {suggestions['characters']}")
            console.print(f"  è¯†åˆ«åœ°ç‚¹: {suggestions['locations']}")
            console.print(f"  å»ºè®®é£æ ¼: {suggestions['suggested_style']}")
            if suggestions.get('character_relationships'):
                console.print(f"  äººç‰©å…³ç³»: {suggestions['character_relationships']}")
        
        # ç”Ÿæˆå¢å¼ºæç¤ºè¯
        enhanced_prompt = prompt_templates.get_enhanced_prompt(
            context=context,
            prompt_type=prompt_type,
            max_length=max_length
        )
        
        console.print(f"\nâœ¨ ç”Ÿæˆçš„{'ä¼ ç»Ÿ' if traditional else 'çŸ¥è¯†å¢å¼º'}æç¤ºè¯:")
        console.print(Panel(
            enhanced_prompt[:800] + "..." if len(enhanced_prompt) > 800 else enhanced_prompt,
            title="ğŸ“ æç¤ºè¯å†…å®¹",
            expand=False
        ))
        
        console.print(f"\nğŸ“ æç¤ºè¯ç»Ÿè®¡:")
        console.print(f"  æ€»é•¿åº¦: {len(enhanced_prompt)} å­—ç¬¦")
        console.print(f"  çº¦ {len(enhanced_prompt) // 100} ç™¾å­—ç¬¦")
        
        if not traditional and suggestions['knowledge_enhanced']:
            console.print("\nğŸ¯ çŸ¥è¯†å¢å¼ºä¼˜åŠ¿:")
            console.print("  âœ… è‡ªåŠ¨è¯†åˆ«æ–‡æœ¬ä¸­çš„äººç‰©å’Œåœ°ç‚¹")
            console.print("  âœ… æä¾›äººç‰©å…³ç³»å’Œæ€§æ ¼èƒŒæ™¯")
            console.print("  âœ… å»ºè®®é€‚åˆçš„å†™ä½œé£æ ¼")
            console.print("  âœ… æ¨èåœºæ™¯ç›¸å…³è§’è‰²")
            console.print("  âœ… åŒ…å«ä¸“ä¸šè¯æ±‡æŒ‡å¯¼")
        
        console.print(f"\nğŸ’¡ æç¤º: è¿™ä¸ªæç¤ºè¯å¯ä»¥ç›´æ¥å‘é€ç»™AIæ¨¡å‹è¿›è¡Œç»­å†™")
        
    except Exception as e:
        console.print(f"[red]çŸ¥è¯†å¢å¼ºç»­å†™æ¼”ç¤ºå¤±è´¥: {e}[/red]")
        logger.error(f"çŸ¥è¯†å¢å¼ºç»­å†™æ¼”ç¤ºå¤±è´¥: {e}")


@cli.command()
@click.option('--extract', is_flag=True, help='é‡æ–°æå–åˆ¤è¯ï¼ˆå¦‚æœå·²å­˜åœ¨ä¼šè¦†ç›–ï¼‰')
@click.option('--character', '-c', help='æŸ¥è¯¢æŒ‡å®šè§’è‰²çš„åˆ¤è¯')
@click.option('--report', is_flag=True, help='ç”Ÿæˆåˆ¤è¯åˆ†ææŠ¥å‘Š')
@click.option('--save-report', help='ä¿å­˜æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶')
def taixu_prophecy(extract, character, report, save_report):
    """å¤ªè™šå¹»å¢ƒåˆ¤è¯æå–ä¸åˆ†æ"""
    console.print(Panel.fit(
        "[bold magenta]å¤ªè™šå¹»å¢ƒåˆ¤è¯åˆ†æç³»ç»Ÿ[/bold magenta]\n"
        "ä»çº¢æ¥¼æ¢¦ç¬¬äº”å›æå–é‡‘é™µåäºŒé’—åˆ¤è¯\n"
        "ä¸ºAIç»­å†™æä¾›æ–‡å­¦æ·±åº¦æŒ‡å¯¼",
        title="ğŸ”® å¤ªè™šå¹»å¢ƒ"
    ))
    
    try:
        extractor = TaixuProphecyExtractor()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æå–åˆ¤è¯
        existing_prophecies = extractor.load_prophecies()
        should_extract = extract or not existing_prophecies
        
        if should_extract:
            console.print("[yellow]å¼€å§‹æå–å¤ªè™šå¹»å¢ƒåˆ¤è¯...[/yellow]")
            
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=console
            ) as progress:
                task = progress.add_task("æå–åˆ¤è¯ä¸­...", total=None)
                
                # æå–åˆ¤è¯
                prophecies = extractor.extract_prophecies_from_chapter5()
                progress.update(task, description="ä¿å­˜åˆ¤è¯æ•°æ®...")
                
                # ä¿å­˜æ•°æ®
                extractor.save_prophecies(prophecies)
                progress.update(task, description="æå–å®Œæˆ!")
            
            console.print("[green]âœ… åˆ¤è¯æå–å®Œæˆ![/green]")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            main_count = len(prophecies.get("main_å†Œ", []))
            secondary_count = len(prophecies.get("å‰¯å†Œ", []))
            tertiary_count = len(prophecies.get("åˆå‰¯å†Œ", []))
            
            console.print(f"\nğŸ“Š æå–ç»Ÿè®¡:")
            console.print(f"  æ­£å†Œåˆ¤è¯: [bold]{main_count}[/bold] ä¸ª")
            console.print(f"  å‰¯å†Œåˆ¤è¯: [bold]{secondary_count}[/bold] ä¸ª")
            console.print(f"  åˆå‰¯å†Œåˆ¤è¯: [bold]{tertiary_count}[/bold] ä¸ª")
            console.print(f"  æ€»è®¡: [bold]{main_count + secondary_count + tertiary_count}[/bold] ä¸ª")
        
        else:
            console.print("[green]ä½¿ç”¨å·²å­˜åœ¨çš„åˆ¤è¯æ•°æ®[/green]")
        
        # æŸ¥è¯¢æŒ‡å®šè§’è‰²çš„åˆ¤è¯
        if character:
            console.print(f"\nğŸ” æŸ¥è¯¢è§’è‰²: [bold]{character}[/bold]")
            
            character_prophecy = extractor.get_character_prophecy(character)
            if character_prophecy:
                console.print(Panel(
                    f"**è§’è‰²**: {', '.join(character_prophecy['characters'])}\n"
                    f"**å†Œåˆ«**: {character_prophecy['å†Œ_type']}\n"
                    f"**ç”»é¢**: {character_prophecy['image']['description']}\n"
                    f"**åˆ¤è¯**: {' / '.join(character_prophecy['poem']['lines'])}\n"
                    f"**å‘½è¿**: {extractor.get_fate_summary(character) or 'æœªæ‰¾åˆ°'}\n"
                    f"**è±¡å¾**: {', '.join(extractor.get_symbolic_elements(character))}",
                    title=f"ğŸ“œ {character}çš„åˆ¤è¯",
                    expand=False
                ))
            else:
                console.print(f"[red]æœªæ‰¾åˆ° {character} çš„åˆ¤è¯ä¿¡æ¯[/red]")
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        if report or save_report:
            console.print("\nğŸ“ ç”Ÿæˆåˆ¤è¯åˆ†ææŠ¥å‘Š...")
            
            report_content = extractor.generate_prophecy_report()
            
            if save_report:
                # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
                report_path = Path(save_report)
                report_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                
                console.print(f"[green]æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}[/green]")
            
            if report:
                # æ˜¾ç¤ºæŠ¥å‘Šå†…å®¹ï¼ˆæˆªå–å‰1000å­—ç¬¦ï¼‰
                display_content = report_content[:1000] + "..." if len(report_content) > 1000 else report_content
                console.print(Panel(
                    display_content,
                    title="ğŸ“Š åˆ¤è¯åˆ†ææŠ¥å‘Š",
                    expand=False
                ))
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹æŸ¥è¯¢å»ºè®®
        if not character and not report and not save_report:
            console.print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
            console.print("  æŸ¥çœ‹æ—é»›ç‰åˆ¤è¯: [bold]python main.py taixu-prophecy -c æ—é»›ç‰[/bold]")
            console.print("  æŸ¥çœ‹è–›å®é’—åˆ¤è¯: [bold]python main.py taixu-prophecy -c è–›å®é’—[/bold]")
            console.print("  ç”Ÿæˆåˆ†ææŠ¥å‘Š: [bold]python main.py taixu-prophecy --report[/bold]")
            console.print("  ä¿å­˜åˆ†ææŠ¥å‘Š: [bold]python main.py taixu-prophecy --save-report reports/prophecy.md[/bold]")
            console.print("  é‡æ–°æå–åˆ¤è¯: [bold]python main.py taixu-prophecy --extract[/bold]")
        
        console.print(f"\nğŸ­ å¤ªè™šå¹»å¢ƒåˆ¤è¯ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼")
        console.print("è¿™äº›åˆ¤è¯å°†ä¸ºAIç»­å†™æä¾›æ·±å±‚çš„æ–‡å­¦æŒ‡å¯¼å’Œå‘½è¿ä¸€è‡´æ€§æ£€éªŒã€‚")
        
    except FileNotFoundError as e:
        console.print(f"[red]æ–‡ä»¶æœªæ‰¾åˆ°: {e}[/red]")
        console.print("è¯·ç¡®ä¿ data/processed/chapters/005.md æ–‡ä»¶å­˜åœ¨")
        logger.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
    except Exception as e:
        console.print(f"[red]å¤ªè™šå¹»å¢ƒåˆ†æå¤±è´¥: {e}[/red]")
        logger.error(f"å¤ªè™šå¹»å¢ƒåˆ†æå¤±è´¥: {e}")


@cli.command()
@click.option('--text', '-t', required=True, help='è¦æ£€éªŒçš„ç»­å†™æ–‡æœ¬')
@click.option('--characters', '-c', help='æŒ‡å®šæ£€æŸ¥çš„è§’è‰²ï¼ˆé€—å·åˆ†éš”ï¼‰')
@click.option('--detailed', is_flag=True, help='ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š')
@click.option('--save-report', help='ä¿å­˜æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶')
@click.option('--guidance', is_flag=True, help='æ˜¾ç¤ºå‘½è¿æŒ‡å¯¼å»ºè®®')
def fate_check(text, characters, detailed, save_report, guidance):
    """å‘½è¿ä¸€è‡´æ€§æ£€éªŒ - åŸºäºå¤ªè™šå¹»å¢ƒåˆ¤è¯éªŒè¯ç»­å†™å†…å®¹"""
    console.print(Panel.fit(
        f"[bold cyan]å‘½è¿ä¸€è‡´æ€§æ£€éªŒç³»ç»Ÿ[/bold cyan]\n"
        f"åŸºäºå¤ªè™šå¹»å¢ƒåˆ¤è¯éªŒè¯ç»­å†™å†…å®¹çš„ä¸€è‡´æ€§\n"
        f"æ£€æµ‹è¿èƒŒåŸè‘—è®¾å®šçš„å†…å®¹å¹¶æä¾›æŒ‡å¯¼å»ºè®®",
        title="ğŸ­ å‘½è¿æ£€éªŒ"
    ))
    
    try:
        # åˆå§‹åŒ–æ£€éªŒå™¨
        checker = FateConsistencyChecker()
        
        # è§£æè§’è‰²å‚æ•°
        character_list = None
        if characters:
            character_list = [char.strip() for char in characters.split(',')]
            console.print(f"[yellow]æŒ‡å®šæ£€æŸ¥è§’è‰²: {', '.join(character_list)}[/yellow]")
        
        console.print(f"\nğŸ“ æ£€éªŒæ–‡æœ¬:")
        console.print(Panel(
            text[:200] + "..." if len(text) > 200 else text,
            title="ç»­å†™å†…å®¹",
            expand=False
        ))
        
        # è¿›è¡Œä¸€è‡´æ€§æ£€éªŒ
        console.print("\nğŸ” æ­£åœ¨è¿›è¡Œå‘½è¿ä¸€è‡´æ€§æ£€éªŒ...")
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("åˆ†æä¸­...", total=None)
            
            # æ‰§è¡Œæ£€éªŒ
            score = checker.check_consistency(text, character_list)
            progress.update(task, description="æ£€éªŒå®Œæˆ!")
        
        # æ˜¾ç¤ºè¯„åˆ†ç»“æœ
        score_emoji = "ğŸ‰" if score.overall_score >= 90 else "âœ…" if score.overall_score >= 70 else "âš ï¸" if score.overall_score >= 50 else "âŒ"
        console.print(f"\nğŸ“Š æ€»ä½“è¯„åˆ†: {score_emoji} [bold]{score.overall_score}/100[/bold]")
        
        # æ˜¾ç¤ºè§’è‰²è¯„åˆ†
        if score.character_scores:
            console.print("\nğŸ‘¥ è§’è‰²ä¸€è‡´æ€§è¯„åˆ†:")
            for character, char_score in score.character_scores.items():
                char_emoji = "âœ…" if char_score >= 80 else "âš ï¸" if char_score >= 60 else "âŒ"
                console.print(f"  {char_emoji} {character}: [bold]{char_score}/100[/bold]")
        
        # æ˜¾ç¤ºæ–¹é¢è¯„åˆ†
        if score.aspect_scores:
            console.print("\nğŸ“ˆ å„æ–¹é¢è¯„åˆ†:")
            for aspect, aspect_score in score.aspect_scores.items():
                aspect_emoji = "âœ…" if aspect_score >= 80 else "âš ï¸" if aspect_score >= 60 else "âŒ"
                console.print(f"  {aspect_emoji} {aspect}: {aspect_score}/100")
        
        # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„é—®é¢˜
        if score.violations:
            console.print("\nğŸš¨ æ£€æµ‹åˆ°çš„é—®é¢˜:")
            
            critical_violations = [v for v in score.violations if v.severity == "critical"]
            warning_violations = [v for v in score.violations if v.severity == "warning"]
            suggestion_violations = [v for v in score.violations if v.severity == "suggestion"]
            
            if critical_violations:
                console.print("\n  âŒ [bold red]ä¸¥é‡é—®é¢˜[/bold red]:")
                for violation in critical_violations:
                    console.print(f"    â€¢ {violation.character}: {violation.description}")
            
            if warning_violations:
                console.print("\n  âš ï¸ [bold yellow]è­¦å‘Šäº‹é¡¹[/bold yellow]:")
                for violation in warning_violations:
                    console.print(f"    â€¢ {violation.character}: {violation.description}")
            
            if suggestion_violations:
                console.print("\n  ğŸ’¡ [bold blue]ä¼˜åŒ–å»ºè®®[/bold blue]:")
                for violation in suggestion_violations:
                    console.print(f"    â€¢ {violation.character}: {violation.description}")
        else:
            console.print("\nâœ¨ [green]æœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼Œç»­å†™å†…å®¹ä¸åˆ¤è¯é¢„è¨€åŸºæœ¬ä¸€è‡´ï¼[/green]")
        
        # æ˜¾ç¤ºæ”¹è¿›å»ºè®®
        if score.recommendations:
            console.print("\nğŸ“‹ æ”¹è¿›å»ºè®®:")
            for i, recommendation in enumerate(score.recommendations, 1):
                console.print(f"  {i}. {recommendation}")
        
        # æ˜¾ç¤ºå‘½è¿æŒ‡å¯¼
        if guidance and score.character_scores:
            console.print("\nğŸ”® å‘½è¿æŒ‡å¯¼å»ºè®®:")
            for character in score.character_scores.keys():
                fate_guidance = checker.get_fate_guidance(character, text)
                if fate_guidance:
                    console.print(Panel(
                        f"**åˆ¤è¯æš—ç¤º**: {fate_guidance.prophecy_hint}\n"
                        f"**å»ºè®®å‘å±•**: {fate_guidance.suggested_development}\n"
                        f"**è±¡å¾å…ƒç´ **: {', '.join(fate_guidance.symbolic_elements[:3])}\n"
                        f"**æƒ…æ„ŸåŸºè°ƒ**: {fate_guidance.emotional_tone}",
                        title=f"ğŸ­ {character}çš„å‘½è¿æŒ‡å¯¼",
                        expand=False
                    ))
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        if save_report or detailed:
            report_content = checker.generate_consistency_report(score, detailed=True)
            
            if save_report:
                report_path = Path(save_report)
                report_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                
                console.print(f"\n[green]è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}[/green]")
            
            if detailed:
                console.print("\nğŸ“„ è¯¦ç»†æŠ¥å‘Š:")
                console.print(Panel(
                    report_content[:1500] + "..." if len(report_content) > 1500 else report_content,
                    title="å‘½è¿ä¸€è‡´æ€§æ£€éªŒè¯¦ç»†æŠ¥å‘Š",
                    expand=False
                ))
        
        # è¯„åˆ†ç­‰çº§è¯´æ˜
        console.print("\nğŸ“š è¯„åˆ†ç­‰çº§è¯´æ˜:")
        console.print("  ğŸ‰ 90-100åˆ†: å®Œå…¨ç¬¦åˆåˆ¤è¯é¢„è¨€")
        console.print("  âœ… 70-89åˆ†: åŸºæœ¬ç¬¦åˆï¼Œè½»å¾®ä¸ä¸€è‡´")
        console.print("  âš ï¸ 50-69åˆ†: éƒ¨åˆ†ç¬¦åˆï¼Œå­˜åœ¨é—®é¢˜")
        console.print("  âŒ 50åˆ†ä»¥ä¸‹: ä¸¥é‡è¿èƒŒåˆ¤è¯é¢„è¨€")
        
        # ä½¿ç”¨å»ºè®®
        if not guidance and not detailed and not save_report:
            console.print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
            console.print("  æŸ¥çœ‹å‘½è¿æŒ‡å¯¼: [bold]python main.py fate-check -t 'æ–‡æœ¬' --guidance[/bold]")
            console.print("  ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š: [bold]python main.py fate-check -t 'æ–‡æœ¬' --detailed[/bold]")
            console.print("  ä¿å­˜åˆ†ææŠ¥å‘Š: [bold]python main.py fate-check -t 'æ–‡æœ¬' --save-report reports/fate.md[/bold]")
            console.print("  æŒ‡å®šæ£€æŸ¥è§’è‰²: [bold]python main.py fate-check -t 'æ–‡æœ¬' -c 'æ—é»›ç‰,è–›å®é’—'[/bold]")
        
        console.print(f"\nğŸ­ å‘½è¿ä¸€è‡´æ€§æ£€éªŒå®Œæˆï¼")
        
    except FileNotFoundError as e:
        console.print(f"[red]æ–‡ä»¶æœªæ‰¾åˆ°: {e}[/red]")
        console.print("è¯·ç¡®ä¿å·²è¿è¡Œ python main.py taixu-prophecy --extract æå–åˆ¤è¯æ•°æ®")
        logger.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
    except Exception as e:
        console.print(f"[red]å‘½è¿ä¸€è‡´æ€§æ£€éªŒå¤±è´¥: {e}[/red]")
        logger.error(f"å‘½è¿ä¸€è‡´æ€§æ£€éªŒå¤±è´¥: {e}")


# ============================================================================
# RAGæ™ºèƒ½æ£€ç´¢ç³»ç»Ÿå‘½ä»¤
# ============================================================================

@cli.group()
def rag():
    """RAGæ™ºèƒ½æ£€ç´¢ç³»ç»Ÿ - åŸºäºQwen3å‘é‡åŒ–çš„è¯­ä¹‰æ£€ç´¢"""
    pass


@rag.command()
@click.option('--reset', is_flag=True, help='é‡ç½®ç°æœ‰å‘é‡æ•°æ®åº“')
@click.option('--api-key', help='DashScope APIå¯†é’¥')
@click.option('--chunk-strategy', default='semantic', 
              type=click.Choice(['semantic', 'paragraph', 'chapter', 'hybrid']),
              help='æ–‡æœ¬åˆ†å—ç­–ç•¥')
@click.option('--chunk-size', default=512, help='åˆ†å—å¤§å°')
@click.option('--batch-size', default=32, help='æ‰¹å¤„ç†å¤§å°')
def build(reset, api_key, chunk_strategy, chunk_size, batch_size):
    """æ„å»ºRAGçŸ¥è¯†åº“ - å¤„ç†ç« èŠ‚æ–‡æœ¬å¹¶åˆ›å»ºå‘é‡ç´¢å¼•"""
    try:
        console.print(Panel.fit("ğŸš€ RAGçŸ¥è¯†åº“æ„å»º", style="bold green"))
        
        if api_key:
            import os
            os.environ['DASHSCOPE_API_KEY'] = api_key
            console.print("âœ… APIå¯†é’¥å·²è®¾ç½®")
        
        # åˆ›å»ºRAGç®¡é“
        pipeline = create_rag_pipeline(
            chunk_strategy=chunk_strategy,
            chunk_config={'chunk_size': chunk_size},
            embedding_config={'batch_size': batch_size}
        )
        
        console.print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
        console.print(f"  åˆ†å—ç­–ç•¥: {chunk_strategy}")
        console.print(f"  åˆ†å—å¤§å°: {chunk_size}")
        console.print(f"  æ‰¹å¤„ç†å¤§å°: {batch_size}")
        
        # æ„å»ºçŸ¥è¯†åº“
        console.print(f"\nğŸ”¨ å¼€å§‹æ„å»ºçŸ¥è¯†åº“...")
        stats = pipeline.build_knowledge_base(reset_existing=reset)
        
        # æ˜¾ç¤ºæ„å»ºç»“æœ
        console.print(f"\nâœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆ!")
        console.print(f"ğŸ“Š æ„å»ºç»Ÿè®¡:")
        console.print(f"  å¤„ç†æ–‡æ¡£: {stats['documents_processed']} ä¸ª")
        console.print(f"  æ–‡æœ¬å—æ•°: {stats['chunks_created']} ä¸ª")
        console.print(f"  å‘é‡æ•°é‡: {stats['embeddings_generated']} ä¸ª")
        console.print(f"  å¤„ç†æ—¶é—´: {stats['processing_time']:.2f} ç§’")
        
        if stats.get('errors'):
            console.print(f"âš ï¸ é”™è¯¯æ•°é‡: {len(stats['errors'])}")
        
        # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡
        db_stats = stats['database_stats']
        console.print(f"\nğŸ“ˆ æ•°æ®åº“ç»Ÿè®¡:")
        console.print(f"  æ€»æ–‡æ¡£æ•°: {db_stats['total_documents']}")
        console.print(f"  å­˜å‚¨è·¯å¾„: {db_stats['db_path']}")
        
    except Exception as e:
        console.print(f"[red]çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}[/red]")
        logger.error(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")


@rag.command()
@click.option('--query', '-q', required=True, help='æ£€ç´¢æŸ¥è¯¢æ–‡æœ¬')
@click.option('--type', 'search_type', default='hybrid',
              type=click.Choice(['semantic', 'text', 'hybrid', 'auto']),
              help='æ£€ç´¢ç±»å‹')
@click.option('--results', '-n', default=5, help='è¿”å›ç»“æœæ•°é‡')
@click.option('--characters', '-c', help='äººç‰©è¿‡æ»¤ï¼ˆé€—å·åˆ†éš”ï¼‰')
@click.option('--semantic-weight', default=0.7, help='è¯­ä¹‰æ£€ç´¢æƒé‡ï¼ˆhybridæ¨¡å¼ï¼‰')
@click.option('--text-weight', default=0.3, help='æ–‡æœ¬æ£€ç´¢æƒé‡ï¼ˆhybridæ¨¡å¼ï¼‰')
@click.option('--threshold', default=0.7, help='ç›¸ä¼¼åº¦é˜ˆå€¼')
def search(query, search_type, results, characters, semantic_weight, text_weight, threshold):
    """RAGæ™ºèƒ½æ£€ç´¢ - è¯­ä¹‰/æ–‡æœ¬/æ··åˆæ£€ç´¢"""
    try:
        console.print(Panel.fit(f"ğŸ” RAGæ™ºèƒ½æ£€ç´¢: {search_type.upper()}", style="bold blue"))
        
        # åˆ›å»ºRAGç®¡é“
        pipeline = create_rag_pipeline()
        
        # å¤„ç†äººç‰©è¿‡æ»¤
        character_filter = None
        if characters:
            character_filter = [c.strip() for c in characters.split(',')]
            console.print(f"ğŸ‘¥ äººç‰©è¿‡æ»¤: {character_filter}")
        
        console.print(f"ğŸ” æŸ¥è¯¢: {query}")
        console.print(f"ğŸ“Š å‚æ•°: ç±»å‹={search_type}, æ•°é‡={results}, é˜ˆå€¼={threshold}")
        
        # æ‰§è¡Œæ£€ç´¢
        search_results = pipeline.search(
            query=query,
            search_type=search_type,
            n_results=results,
            character_filter=character_filter,
            semantic_weight=semantic_weight,
            text_weight=text_weight
        )
        
        # æ˜¾ç¤ºç»“æœ
        console.print(f"\nğŸ“‹ æ£€ç´¢ç»“æœ ({len(search_results['documents'])} ä¸ª):")
        
        for i, (doc, sim, meta) in enumerate(zip(
            search_results['documents'],
            search_results['similarities'], 
            search_results['metadatas']
        )):
            console.print(f"\nğŸ“„ ç»“æœ {i+1}:")
            console.print(f"  ğŸ“Š ç›¸ä¼¼åº¦: {sim:.3f}")
            
            if meta.get('characters'):
                console.print(f"  ğŸ‘¥ äººç‰©: {', '.join(meta['characters'])}")
            
            if meta.get('source_id'):
                console.print(f"  ğŸ“– æ¥æº: {meta['source_id']}")
            
            # æ–‡æœ¬é¢„è§ˆ
            preview = doc[:200] + "..." if len(doc) > 200 else doc
            console.print(f"  ğŸ“ å†…å®¹: {preview}")
            
            # æ··åˆæ£€ç´¢æ˜¾ç¤ºè¯¦ç»†åˆ†æ•°
            if search_type == 'hybrid' and 'semantic_scores' in search_results:
                sem_score = search_results['semantic_scores'][i]
                text_score = search_results['text_scores'][i]
                console.print(f"    ğŸ” è¯­ä¹‰: {sem_score:.3f} | ğŸ“ æ–‡æœ¬: {text_score:.3f}")
        
        if not search_results['documents']:
            console.print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„ç»“æœï¼Œå»ºè®®ï¼š")
            console.print("  - é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼")
            console.print("  - å°è¯•ä¸åŒçš„æ£€ç´¢ç±»å‹")
            console.print("  - æ£€æŸ¥æŸ¥è¯¢å†…å®¹æ˜¯å¦å‡†ç¡®")
            
    except Exception as e:
        console.print(f"[red]æ£€ç´¢å¤±è´¥: {e}[/red]")
        logger.error(f"æ£€ç´¢å¤±è´¥: {e}")


@rag.command()
@click.option('--query', default='å®ç‰å’Œé»›ç‰çš„å…³ç³»', help='æµ‹è¯•æŸ¥è¯¢')
def test(query):
    """å¿«é€Ÿæµ‹è¯•RAGç³»ç»Ÿ"""
    try:
        console.print(Panel.fit("ğŸ§ª RAGç³»ç»Ÿå¿«é€Ÿæµ‹è¯•", style="bold magenta"))
        
        # åˆ›å»ºRAGç®¡é“
        pipeline = create_rag_pipeline()
        
        # æ‰§è¡Œå¿«é€Ÿæµ‹è¯•
        pipeline.quick_test(query)
        
    except Exception as e:
        console.print(f"[red]æµ‹è¯•å¤±è´¥: {e}[/red]")
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")


@rag.command()
@click.option('--output-dir', default='exports/rag_export', help='å¯¼å‡ºç›®å½•')
def export(output_dir):
    """å¯¼å‡ºRAGçŸ¥è¯†åº“"""
    try:
        console.print(Panel.fit("ğŸ“¦ å¯¼å‡ºRAGçŸ¥è¯†åº“", style="bold cyan"))
        
        # åˆ›å»ºRAGç®¡é“
        pipeline = create_rag_pipeline()
        
        # å¯¼å‡ºçŸ¥è¯†åº“
        pipeline.export_knowledge_base(output_dir)
        
        console.print(f"âœ… çŸ¥è¯†åº“å·²å¯¼å‡ºåˆ°: {output_dir}")
        
    except Exception as e:
        console.print(f"[red]å¯¼å‡ºå¤±è´¥: {e}[/red]")
        logger.error(f"å¯¼å‡ºå¤±è´¥: {e}")


@rag.command()
def status():
    """æŸ¥çœ‹RAGç³»ç»ŸçŠ¶æ€"""
    try:
        console.print(Panel.fit("ğŸ“Š RAGç³»ç»ŸçŠ¶æ€", style="bold yellow"))
        
        # åˆ›å»ºRAGç®¡é“
        pipeline = create_rag_pipeline()
        
        # è·å–ç³»ç»ŸçŠ¶æ€
        status_info = pipeline.get_system_status()
        
        console.print("ğŸ”§ ç®¡é“é…ç½®:")
        pipeline_config = status_info['pipeline_config']
        console.print(f"  å‘é‡æ¨¡å‹: {pipeline_config['embedding_model']}")
        console.print(f"  åˆ†å—ç­–ç•¥: {pipeline_config['chunk_strategy']}")
        console.print(f"  åˆ†å—å¤§å°: {pipeline_config['chunk_size']}")
        console.print(f"  æ•°æ®åº“è·¯å¾„: {pipeline_config['db_path']}")
        
        console.print("\nğŸ“ˆ æ•°æ®åº“ç»Ÿè®¡:")
        db_stats = status_info['database_stats']
        console.print(f"  æ€»æ–‡æ¡£æ•°: {db_stats['total_documents']}")
        console.print(f"  è·ç¦»åº¦é‡: {db_stats['distance_metric']}")
        
        if db_stats.get('top_characters'):
            console.print("\nğŸ‘¥ ä¸»è¦äººç‰©åˆ†å¸ƒ:")
            for char, count in db_stats['top_characters'][:5]:
                console.print(f"  {char}: {count} ä¸ªæ–‡æœ¬å—")
        
        console.print(f"\nğŸ“ æ–‡æœ¬å—ç»Ÿè®¡:")
        console.print(f"  å¯¹è¯å—: {db_stats.get('dialogue_chunks', 0)}")
        console.print(f"  ç« èŠ‚å¤´: {db_stats.get('chapter_chunks', 0)}")
        
    except Exception as e:
        console.print(f"[red]çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {e}[/red]")
        logger.error(f"çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {e}")


if __name__ == "__main__":
    cli()