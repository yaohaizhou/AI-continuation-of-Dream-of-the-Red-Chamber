"""
å®æ—¶æ–‡é£ä¼˜åŒ–å™¨

åŸºäºé£æ ¼ç›¸ä¼¼åº¦è¯„ä¼°ç»“æœï¼ŒåŠ¨æ€è°ƒæ•´è½¬æ¢ç­–ç•¥ï¼Œå®ç°æ–‡é£è´¨é‡çš„
è¿­ä»£ä¼˜åŒ–å’Œå®æ—¶ç›‘æ§ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
- è¯„ä¼°ç»“æœåˆ†æï¼šè§£æè¯„ä¼°åé¦ˆï¼Œè¯†åˆ«ä¼˜åŒ–æ–¹å‘
- åŠ¨æ€ç­–ç•¥è°ƒæ•´ï¼šæ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´è½¬æ¢å™¨å‚æ•°
- è¿­ä»£ä¼˜åŒ–å¾ªç¯ï¼šå¤šè½®ä¼˜åŒ–ç›´åˆ°è¾¾åˆ°ç›®æ ‡è´¨é‡
- å®æ—¶è´¨é‡ç›‘æ§ï¼šæŒç»­ç›‘æ§å’Œåé¦ˆä¼˜åŒ–æ•ˆæœ
"""

import time
import json
import logging
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, asdict
from collections import defaultdict
from enum import Enum

from .intelligent_style_converter import IntelligentStyleConverter, ConversionConfig, ConversionResult
from .style_similarity_evaluator import StyleSimilarityEvaluator, EvaluationResult, SimilarityScores

class OptimizationStrategy(Enum):
    """ä¼˜åŒ–ç­–ç•¥ç±»å‹"""
    VOCABULARY_ENHANCEMENT = "vocabulary_enhancement"      # è¯æ±‡å¢å¼º
    SENTENCE_RESTRUCTURING = "sentence_restructuring"      # å¥å¼é‡æ„
    RHETORICAL_IMPROVEMENT = "rhetorical_improvement"      # ä¿®è¾æ”¹è¿›
    ADDRESSING_CORRECTION = "addressing_correction"        # ç§°è°“çº æ­£
    COMPREHENSIVE_OPTIMIZATION = "comprehensive_optimization"  # ç»¼åˆä¼˜åŒ–

class OptimizationResult(Enum):
    """ä¼˜åŒ–ç»“æœçŠ¶æ€"""
    SUCCESS = "success"           # ä¼˜åŒ–æˆåŠŸ
    IMPROVED = "improved"         # æœ‰æ”¹è¿›ä½†æœªè¾¾æ ‡
    NO_IMPROVEMENT = "no_improvement"  # æ— æ”¹è¿›
    DEGRADED = "degraded"         # è´¨é‡ä¸‹é™
    MAX_ITERATIONS = "max_iterations"  # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°

@dataclass
class OptimizationConfig:
    """ä¼˜åŒ–é…ç½®"""
    target_score: float = 70.0              # ç›®æ ‡è¯„åˆ†
    max_iterations: int = 5                 # æœ€å¤§è¿­ä»£æ¬¡æ•°
    improvement_threshold: float = 2.0      # æ”¹è¿›é˜ˆå€¼
    convergence_threshold: float = 1.0      # æ”¶æ•›é˜ˆå€¼
    aggressive_mode: bool = False           # æ¿€è¿›æ¨¡å¼
    preserve_meaning: bool = True           # ä¿æŒè¯­ä¹‰
    enable_rhetorical_enhancement: bool = True  # å¯ç”¨ä¿®è¾å¢å¼º

@dataclass
class OptimizationStep:
    """ä¼˜åŒ–æ­¥éª¤è®°å½•"""
    iteration: int                          # è¿­ä»£è½®æ¬¡
    strategy: OptimizationStrategy          # ä½¿ç”¨çš„ç­–ç•¥
    config_changes: Dict[str, Any]          # é…ç½®å˜æ›´
    before_score: float                     # ä¼˜åŒ–å‰è¯„åˆ†
    after_score: float                      # ä¼˜åŒ–åè¯„åˆ†
    improvement: float                      # æ”¹è¿›å¹…åº¦
    text_before: str                        # ä¼˜åŒ–å‰æ–‡æœ¬
    text_after: str                         # ä¼˜åŒ–åæ–‡æœ¬
    processing_time: float                  # å¤„ç†æ—¶é—´

@dataclass
class OptimizationSession:
    """ä¼˜åŒ–ä¼šè¯è®°å½•"""
    original_text: str                      # åŸå§‹æ–‡æœ¬
    final_text: str                         # æœ€ç»ˆæ–‡æœ¬
    initial_score: float                    # åˆå§‹è¯„åˆ†
    final_score: float                      # æœ€ç»ˆè¯„åˆ†
    total_improvement: float                # æ€»æ”¹è¿›å¹…åº¦
    iterations_used: int                    # å®é™…è¿­ä»£æ¬¡æ•°
    optimization_steps: List[OptimizationStep]  # ä¼˜åŒ–æ­¥éª¤
    result_status: OptimizationResult       # ç»“æœçŠ¶æ€
    total_time: float                       # æ€»è€—æ—¶
    strategies_used: List[OptimizationStrategy]  # ä½¿ç”¨çš„ç­–ç•¥

@dataclass
class BatchOptimizationResult:
    """æ‰¹é‡ä¼˜åŒ–ç»“æœ"""
    total_texts: int                        # æ€»æ–‡æœ¬æ•°
    successful_optimizations: int          # æˆåŠŸä¼˜åŒ–æ•°
    average_improvement: float              # å¹³å‡æ”¹è¿›å¹…åº¦
    optimization_sessions: List[OptimizationSession]  # ä¼˜åŒ–ä¼šè¯åˆ—è¡¨
    strategy_effectiveness: Dict[str, float]  # ç­–ç•¥æœ‰æ•ˆæ€§
    processing_statistics: Dict[str, Any]  # å¤„ç†ç»Ÿè®¡

class RealtimeStyleOptimizer:
    """å®æ—¶æ–‡é£ä¼˜åŒ–å™¨"""
    
    def __init__(self, 
                 converter: Optional[IntelligentStyleConverter] = None,
                 evaluator: Optional[StyleSimilarityEvaluator] = None,
                 config: Optional[OptimizationConfig] = None):
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.converter = converter or IntelligentStyleConverter()
        self.evaluator = evaluator or StyleSimilarityEvaluator()
        self.config = config or OptimizationConfig()
        
        # ä¼˜åŒ–å†å²
        self.optimization_history: List[OptimizationSession] = []
        
        # ç­–ç•¥é…ç½®æ˜ å°„
        self._init_strategy_mappings()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_optimizations': 0,
            'successful_optimizations': 0,
            'average_improvement': 0.0,
            'strategy_success_rates': defaultdict(list)
        }
        
    def _init_strategy_mappings(self):
        """åˆå§‹åŒ–ç­–ç•¥é…ç½®æ˜ å°„"""
        
        # è¯æ±‡å¢å¼ºç­–ç•¥
        self.vocabulary_strategies = {
            'low_classical_ratio': {
                'vocabulary_level': 'high',
                'preserve_meaning': True,
                'character_context': None
            },
            'modern_words_detected': {
                'vocabulary_level': 'high',
                'aggressive_replacement': True
            }
        }
        
        # å¥å¼é‡æ„ç­–ç•¥
        self.sentence_strategies = {
            'short_sentences': {
                'sentence_restructure': True,
                'add_classical_openings': True,
                'expand_sentences': True
            },
            'low_complexity': {
                'sentence_restructure': True,
                'classical_sentence_patterns': True
            }
        }
        
        # ä¿®è¾æ”¹è¿›ç­–ç•¥
        self.rhetorical_strategies = {
            'no_metaphors': {
                'add_rhetorical_devices': True,
                'metaphor_enhancement': True,
                'simile_enhancement': True
            },
            'no_parallelism': {
                'add_rhetorical_devices': True,
                'parallelism_enhancement': True
            }
        }
        
        # ç§°è°“çº æ­£ç­–ç•¥
        self.addressing_strategies = {
            'inconsistent_addressing': {
                'character_context': 'formal',
                'scene_context': 'formal_occasion',
                'addressing_consistency': True
            }
        }
        
    def optimize_text(self, 
                     text: str, 
                     config: Optional[OptimizationConfig] = None) -> OptimizationSession:
        """ä¼˜åŒ–å•ä¸ªæ–‡æœ¬çš„é£æ ¼"""
        
        start_time = time.time()
        opt_config = config or self.config
        
        self.logger.info(f"å¼€å§‹ä¼˜åŒ–æ–‡æœ¬ï¼Œç›®æ ‡è¯„åˆ†: {opt_config.target_score}")
        
        # åˆå§‹è¯„ä¼°
        current_text = text
        initial_evaluation = self.evaluator.evaluate_similarity(text, detailed=True)
        initial_score = initial_evaluation.similarity_scores.total_score
        
        self.logger.info(f"åˆå§‹è¯„åˆ†: {initial_score:.1f}")
        
        # ä¼˜åŒ–æ­¥éª¤è®°å½•
        optimization_steps = []
        strategies_used = []
        
        # è¿­ä»£ä¼˜åŒ–
        for iteration in range(opt_config.max_iterations):
            self.logger.info(f"å¼€å§‹ç¬¬{iteration + 1}è½®ä¼˜åŒ–")
            
            # åˆ†æå½“å‰è¯„ä¼°ç»“æœ
            strategy, config_changes = self._analyze_evaluation_and_plan_strategy(
                initial_evaluation if iteration == 0 else current_evaluation,
                opt_config
            )
            
            if strategy is None:
                self.logger.info("æœªæ‰¾åˆ°åˆé€‚çš„ä¼˜åŒ–ç­–ç•¥ï¼Œåœæ­¢ä¼˜åŒ–")
                break
            
            strategies_used.append(strategy)
            
            # åº”ç”¨ä¼˜åŒ–ç­–ç•¥
            step_start_time = time.time()
            before_score = current_evaluation.similarity_scores.total_score if iteration > 0 else initial_score
            
            optimized_text = self._apply_optimization_strategy(
                current_text, strategy, config_changes
            )
            
            # è¯„ä¼°ä¼˜åŒ–æ•ˆæœ
            current_evaluation = self.evaluator.evaluate_similarity(optimized_text, detailed=True)
            after_score = current_evaluation.similarity_scores.total_score
            improvement = after_score - before_score
            
            step_time = time.time() - step_start_time
            
            # è®°å½•ä¼˜åŒ–æ­¥éª¤
            step = OptimizationStep(
                iteration=iteration + 1,
                strategy=strategy,
                config_changes=config_changes,
                before_score=before_score,
                after_score=after_score,
                improvement=improvement,
                text_before=current_text,
                text_after=optimized_text,
                processing_time=step_time
            )
            optimization_steps.append(step)
            
            self.logger.info(
                f"ç¬¬{iteration + 1}è½®å®Œæˆ - ç­–ç•¥: {strategy.value}, "
                f"è¯„åˆ†: {before_score:.1f} â†’ {after_score:.1f} "
                f"(æ”¹è¿›: {improvement:+.1f})"
            )
            
            # æ£€æŸ¥ä¼˜åŒ–æ•ˆæœ
            if after_score >= opt_config.target_score:
                result_status = OptimizationResult.SUCCESS
                current_text = optimized_text
                break
            elif improvement >= opt_config.improvement_threshold:
                result_status = OptimizationResult.IMPROVED
                current_text = optimized_text
            elif improvement < 0:
                self.logger.warning(f"ç¬¬{iteration + 1}è½®ä¼˜åŒ–å¯¼è‡´è´¨é‡ä¸‹é™ï¼Œå›é€€åˆ°ä¸Šä¸€ç‰ˆæœ¬")
                result_status = OptimizationResult.DEGRADED
                break
            elif abs(improvement) < opt_config.convergence_threshold:
                self.logger.info("ä¼˜åŒ–æ”¶æ•›ï¼Œåœæ­¢è¿­ä»£")
                result_status = OptimizationResult.NO_IMPROVEMENT
                current_text = optimized_text
                break
            else:
                current_text = optimized_text
                result_status = OptimizationResult.IMPROVED
        else:
            result_status = OptimizationResult.MAX_ITERATIONS
        
        # åˆ›å»ºä¼˜åŒ–ä¼šè¯è®°å½•
        final_evaluation = self.evaluator.evaluate_similarity(current_text, detailed=True)
        final_score = final_evaluation.similarity_scores.total_score
        total_time = time.time() - start_time
        
        session = OptimizationSession(
            original_text=text,
            final_text=current_text,
            initial_score=initial_score,
            final_score=final_score,
            total_improvement=final_score - initial_score,
            iterations_used=len(optimization_steps),
            optimization_steps=optimization_steps,
            result_status=result_status,
            total_time=total_time,
            strategies_used=strategies_used
        )
        
        # æ·»åŠ åˆ°å†å²è®°å½•
        self.optimization_history.append(session)
        
        # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
        self._update_performance_stats(session)
        
        self.logger.info(
            f"ä¼˜åŒ–å®Œæˆ - æœ€ç»ˆè¯„åˆ†: {final_score:.1f} "
            f"(æ€»æ”¹è¿›: {session.total_improvement:+.1f}), "
            f"çŠ¶æ€: {result_status.value}"
        )
        
        return session
    
    def _analyze_evaluation_and_plan_strategy(self, 
                                            evaluation: EvaluationResult,
                                            config: OptimizationConfig) -> Tuple[Optional[OptimizationStrategy], Dict[str, Any]]:
        """åˆ†æè¯„ä¼°ç»“æœå¹¶åˆ¶å®šä¼˜åŒ–ç­–ç•¥"""
        
        scores = evaluation.similarity_scores
        suggestions = evaluation.improvement_suggestions
        
        # æ‰¾å‡ºæœ€éœ€è¦æ”¹è¿›çš„ç»´åº¦
        dimension_scores = {
            'vocabulary': scores.vocabulary_similarity,
            'sentence': scores.sentence_similarity,
            'rhetorical': scores.rhetorical_similarity,
            'addressing': scores.addressing_similarity
        }
        
        # æŒ‰åˆ†æ•°æ’åºï¼Œä¼˜å…ˆæ”¹è¿›åˆ†æ•°æœ€ä½çš„ç»´åº¦
        sorted_dimensions = sorted(dimension_scores.items(), key=lambda x: x[1])
        lowest_dimension, lowest_score = sorted_dimensions[0]
        
        self.logger.info(f"ä¼˜å…ˆæ”¹è¿›ç»´åº¦: {lowest_dimension} (å½“å‰åˆ†æ•°: {lowest_score:.3f})")
        
        # æ ¹æ®æœ€ä½åˆ†ç»´åº¦é€‰æ‹©ç­–ç•¥
        if lowest_dimension == 'vocabulary' and lowest_score < 0.6:
            return self._plan_vocabulary_strategy(evaluation, config)
        elif lowest_dimension == 'sentence' and lowest_score < 0.6:
            return self._plan_sentence_strategy(evaluation, config)
        elif lowest_dimension == 'rhetorical' and lowest_score < 0.5:
            return self._plan_rhetorical_strategy(evaluation, config)
        elif lowest_dimension == 'addressing' and lowest_score < 0.7:
            return self._plan_addressing_strategy(evaluation, config)
        else:
            # å¦‚æœå„ç»´åº¦éƒ½ä¸ç®—å¤ªä½ï¼Œè¿›è¡Œç»¼åˆä¼˜åŒ–
            return self._plan_comprehensive_strategy(evaluation, config)
    
    def _plan_vocabulary_strategy(self, evaluation: EvaluationResult, config: OptimizationConfig) -> Tuple[OptimizationStrategy, Dict[str, Any]]:
        """åˆ¶å®šè¯æ±‡ä¼˜åŒ–ç­–ç•¥"""
        
        analysis = evaluation.detailed_analysis.get('vocabulary_analysis', {})
        classical_ratio = analysis.get('classical_word_ratio', 0)
        modern_words = analysis.get('modern_words_detected', 0)
        
        config_changes = {
            'vocabulary_level': 'high',
            'preserve_meaning': config.preserve_meaning
        }
        
        if classical_ratio < 0.3:
            config_changes['aggressive_classical_replacement'] = True
        
        if modern_words > 0:
            config_changes['modern_word_elimination'] = True
        
        return OptimizationStrategy.VOCABULARY_ENHANCEMENT, config_changes
    
    def _plan_sentence_strategy(self, evaluation: EvaluationResult, config: OptimizationConfig) -> Tuple[OptimizationStrategy, Dict[str, Any]]:
        """åˆ¶å®šå¥å¼ä¼˜åŒ–ç­–ç•¥"""
        
        analysis = evaluation.detailed_analysis.get('text_statistics', {})
        avg_length = analysis.get('avg_sentence_length', 0)
        complexity = analysis.get('sentence_complexity', 0)
        
        config_changes = {
            'sentence_restructure': True,
            'preserve_meaning': config.preserve_meaning
        }
        
        if avg_length < 15:
            config_changes['expand_sentences'] = True
            config_changes['add_classical_openings'] = True
        
        if complexity < 0.5:
            config_changes['increase_complexity'] = True
            config_changes['classical_sentence_patterns'] = True
        
        return OptimizationStrategy.SENTENCE_RESTRUCTURING, config_changes
    
    def _plan_rhetorical_strategy(self, evaluation: EvaluationResult, config: OptimizationConfig) -> Tuple[OptimizationStrategy, Dict[str, Any]]:
        """åˆ¶å®šä¿®è¾ä¼˜åŒ–ç­–ç•¥"""
        
        analysis = evaluation.detailed_analysis.get('rhetorical_analysis', {})
        metaphor_count = analysis.get('metaphor_count', 0)
        parallelism_count = analysis.get('parallelism_count', 0)
        
        config_changes = {
            'add_rhetorical_devices': True,
            'preserve_meaning': config.preserve_meaning
        }
        
        if metaphor_count == 0:
            config_changes['metaphor_enhancement'] = True
            config_changes['simile_enhancement'] = True
        
        if parallelism_count == 0:
            config_changes['parallelism_enhancement'] = True
            config_changes['repetition_enhancement'] = True
        
        return OptimizationStrategy.RHETORICAL_IMPROVEMENT, config_changes
    
    def _plan_addressing_strategy(self, evaluation: EvaluationResult, config: OptimizationConfig) -> Tuple[OptimizationStrategy, Dict[str, Any]]:
        """åˆ¶å®šç§°è°“ä¼˜åŒ–ç­–ç•¥"""
        
        config_changes = {
            'character_context': 'formal',
            'scene_context': 'formal_occasion',
            'addressing_consistency': True,
            'preserve_meaning': config.preserve_meaning
        }
        
        return OptimizationStrategy.ADDRESSING_CORRECTION, config_changes
    
    def _plan_comprehensive_strategy(self, evaluation: EvaluationResult, config: OptimizationConfig) -> Tuple[Optional[OptimizationStrategy], Dict[str, Any]]:
        """åˆ¶å®šç»¼åˆä¼˜åŒ–ç­–ç•¥"""
        
        # å¦‚æœåˆ†æ•°å·²ç»å¾ˆé«˜ï¼Œå¯èƒ½ä¸éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–
        if evaluation.similarity_scores.total_score >= config.target_score * 0.95:
            return None, {}
        
        config_changes = {
            'vocabulary_level': 'high',
            'sentence_restructure': True,
            'add_rhetorical_devices': config.enable_rhetorical_enhancement,
            'preserve_meaning': config.preserve_meaning,
            'comprehensive_optimization': True
        }
        
        return OptimizationStrategy.COMPREHENSIVE_OPTIMIZATION, config_changes
    
    def _apply_optimization_strategy(self, 
                                   text: str, 
                                   strategy: OptimizationStrategy, 
                                   config_changes: Dict[str, Any]) -> str:
        """åº”ç”¨ä¼˜åŒ–ç­–ç•¥"""
        
        # åˆ›å»ºè½¬æ¢é…ç½®
        conversion_config = ConversionConfig(
            vocabulary_level=config_changes.get('vocabulary_level', 'medium'),
            sentence_restructure=config_changes.get('sentence_restructure', False),
            add_rhetorical_devices=config_changes.get('add_rhetorical_devices', False),
            preserve_meaning=config_changes.get('preserve_meaning', True),
            character_context=config_changes.get('character_context'),
            scene_context=config_changes.get('scene_context')
        )
        
        # æ‰§è¡Œè½¬æ¢
        result = self.converter.convert_text(text, conversion_config)
        return result.converted_text
    
    def batch_optimize(self, 
                      texts: List[str], 
                      config: Optional[OptimizationConfig] = None) -> BatchOptimizationResult:
        """æ‰¹é‡ä¼˜åŒ–æ–‡æœ¬"""
        
        self.logger.info(f"å¼€å§‹æ‰¹é‡ä¼˜åŒ– {len(texts)} ä¸ªæ–‡æœ¬")
        
        opt_config = config or self.config
        sessions = []
        successful_count = 0
        total_improvement = 0.0
        strategy_performance = defaultdict(list)
        
        start_time = time.time()
        
        for i, text in enumerate(texts):
            try:
                self.logger.info(f"ä¼˜åŒ–ç¬¬ {i+1}/{len(texts)} ä¸ªæ–‡æœ¬")
                session = self.optimize_text(text, opt_config)
                sessions.append(session)
                
                if session.result_status in [OptimizationResult.SUCCESS, OptimizationResult.IMPROVED]:
                    successful_count += 1
                    total_improvement += session.total_improvement
                
                # è®°å½•ç­–ç•¥æ€§èƒ½
                for strategy in session.strategies_used:
                    strategy_performance[strategy.value].append(session.total_improvement)
                
            except Exception as e:
                self.logger.error(f"ä¼˜åŒ–ç¬¬ {i+1} ä¸ªæ–‡æœ¬å¤±è´¥: {e}")
        
        # è®¡ç®—ç­–ç•¥æœ‰æ•ˆæ€§
        strategy_effectiveness = {}
        for strategy, improvements in strategy_performance.items():
            if improvements:
                strategy_effectiveness[strategy] = np.mean(improvements)
        
        # å¤„ç†ç»Ÿè®¡
        total_time = time.time() - start_time
        processing_stats = {
            'total_time': total_time,
            'average_time_per_text': total_time / len(texts) if texts else 0,
            'success_rate': successful_count / len(texts) if texts else 0,
            'average_iterations': np.mean([s.iterations_used for s in sessions]) if sessions else 0
        }
        
        batch_result = BatchOptimizationResult(
            total_texts=len(texts),
            successful_optimizations=successful_count,
            average_improvement=total_improvement / successful_count if successful_count > 0 else 0,
            optimization_sessions=sessions,
            strategy_effectiveness=strategy_effectiveness,
            processing_statistics=processing_stats
        )
        
        self.logger.info(
            f"æ‰¹é‡ä¼˜åŒ–å®Œæˆ - æˆåŠŸ: {successful_count}/{len(texts)}, "
            f"å¹³å‡æ”¹è¿›: {batch_result.average_improvement:.1f}"
        )
        
        return batch_result
    
    def monitor_quality_realtime(self, 
                               text: str, 
                               quality_threshold: float = 70.0,
                               monitor_interval: float = 0.1) -> Dict[str, Any]:
        """å®æ—¶è´¨é‡ç›‘æ§"""
        
        self.logger.info("å¼€å§‹å®æ—¶è´¨é‡ç›‘æ§")
        
        monitoring_data = {
            'start_time': time.time(),
            'quality_timeline': [],
            'alerts': [],
            'final_status': None
        }
        
        # åˆå§‹è¯„ä¼°
        evaluation = self.evaluator.evaluate_similarity(text, detailed=False)
        initial_score = evaluation.similarity_scores.total_score
        
        monitoring_data['quality_timeline'].append({
            'timestamp': time.time() - monitoring_data['start_time'],
            'score': initial_score,
            'status': 'initial'
        })
        
        if initial_score < quality_threshold:
            monitoring_data['alerts'].append({
                'timestamp': time.time() - monitoring_data['start_time'],
                'type': 'quality_alert',
                'message': f"æ–‡æœ¬è´¨é‡ä½äºé˜ˆå€¼ ({initial_score:.1f} < {quality_threshold})",
                'severity': 'warning'
            })
            
            # è‡ªåŠ¨ä¼˜åŒ–
            self.logger.info("è§¦å‘è‡ªåŠ¨ä¼˜åŒ–")
            session = self.optimize_text(text, OptimizationConfig(target_score=quality_threshold))
            
            # è®°å½•ä¼˜åŒ–è¿‡ç¨‹
            for step in session.optimization_steps:
                monitoring_data['quality_timeline'].append({
                    'timestamp': time.time() - monitoring_data['start_time'],
                    'score': step.after_score,
                    'status': f'optimization_step_{step.iteration}',
                    'strategy': step.strategy.value
                })
            
            final_score = session.final_score
            if final_score >= quality_threshold:
                monitoring_data['final_status'] = 'quality_achieved'
                monitoring_data['alerts'].append({
                    'timestamp': time.time() - monitoring_data['start_time'],
                    'type': 'success',
                    'message': f"è´¨é‡ç›®æ ‡å·²è¾¾æˆ ({final_score:.1f})",
                    'severity': 'info'
                })
            else:
                monitoring_data['final_status'] = 'quality_not_achieved'
                monitoring_data['alerts'].append({
                    'timestamp': time.time() - monitoring_data['start_time'],
                    'type': 'optimization_failed',
                    'message': f"ä¼˜åŒ–åä»æœªè¾¾æ ‡ ({final_score:.1f} < {quality_threshold})",
                    'severity': 'error'
                })
        else:
            monitoring_data['final_status'] = 'quality_ok'
            monitoring_data['alerts'].append({
                'timestamp': time.time() - monitoring_data['start_time'],
                'type': 'quality_ok',
                'message': f"æ–‡æœ¬è´¨é‡è¾¾æ ‡ ({initial_score:.1f})",
                'severity': 'info'
            })
        
        total_time = time.time() - monitoring_data['start_time']
        monitoring_data['total_monitoring_time'] = total_time
        
        self.logger.info(f"å®æ—¶ç›‘æ§å®Œæˆï¼Œè€—æ—¶: {total_time:.3f}ç§’")
        
        return monitoring_data
    
    def _update_performance_stats(self, session: OptimizationSession):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        
        self.performance_stats['total_optimizations'] += 1
        
        if session.result_status in [OptimizationResult.SUCCESS, OptimizationResult.IMPROVED]:
            self.performance_stats['successful_optimizations'] += 1
        
        # æ›´æ–°å¹³å‡æ”¹è¿›
        total_improvement = (
            self.performance_stats['average_improvement'] * (self.performance_stats['total_optimizations'] - 1) +
            session.total_improvement
        ) / self.performance_stats['total_optimizations']
        self.performance_stats['average_improvement'] = total_improvement
        
        # è®°å½•ç­–ç•¥æˆåŠŸç‡
        for strategy in session.strategies_used:
            improvement = session.total_improvement if session.total_improvement > 0 else 0
            self.performance_stats['strategy_success_rates'][strategy.value].append(improvement)
    
    def get_optimization_statistics(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        
        if not self.optimization_history:
            return {}
        
        # åŸºç¡€ç»Ÿè®¡
        total_sessions = len(self.optimization_history)
        successful_sessions = sum(
            1 for s in self.optimization_history 
            if s.result_status in [OptimizationResult.SUCCESS, OptimizationResult.IMPROVED]
        )
        
        improvements = [s.total_improvement for s in self.optimization_history]
        iterations = [s.iterations_used for s in self.optimization_history]
        times = [s.total_time for s in self.optimization_history]
        
        # ç­–ç•¥ç»Ÿè®¡
        strategy_usage = defaultdict(int)
        strategy_improvements = defaultdict(list)
        
        for session in self.optimization_history:
            for strategy in session.strategies_used:
                strategy_usage[strategy.value] += 1
                strategy_improvements[strategy.value].append(session.total_improvement)
        
        strategy_stats = {}
        for strategy, usage_count in strategy_usage.items():
            improvements_list = strategy_improvements[strategy]
            strategy_stats[strategy] = {
                'usage_count': usage_count,
                'average_improvement': np.mean(improvements_list) if improvements_list else 0,
                'success_rate': sum(1 for imp in improvements_list if imp > 0) / len(improvements_list) if improvements_list else 0
            }
        
        return {
            'total_optimizations': total_sessions,
            'successful_optimizations': successful_sessions,
            'success_rate': successful_sessions / total_sessions if total_sessions > 0 else 0,
            'average_improvement': np.mean(improvements) if improvements else 0,
            'improvement_std': np.std(improvements) if improvements else 0,
            'improvement_range': (min(improvements), max(improvements)) if improvements else (0, 0),
            'average_iterations': np.mean(iterations) if iterations else 0,
            'average_time': np.mean(times) if times else 0,
            'strategy_statistics': strategy_stats
        }
    
    def save_optimization_history(self, file_path: str):
        """ä¿å­˜ä¼˜åŒ–å†å²"""
        
        try:
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            history_data = []
            for session in self.optimization_history:
                session_dict = asdict(session)
                # è½¬æ¢æšä¸¾å€¼
                session_dict['result_status'] = session.result_status.value
                session_dict['strategies_used'] = [s.value for s in session.strategies_used]
                
                for step in session_dict['optimization_steps']:
                    step['strategy'] = step['strategy'].value if hasattr(step['strategy'], 'value') else step['strategy']
                
                history_data.append(session_dict)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(history_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ä¼˜åŒ–å†å²å·²ä¿å­˜åˆ°: {file_path}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜ä¼˜åŒ–å†å²å¤±è´¥: {e}")
    
    def generate_optimization_report(self, file_path: str, batch_result: Optional[BatchOptimizationResult] = None):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        
        stats = self.get_optimization_statistics()
        
        report_content = f"""# å®æ—¶æ–‡é£ä¼˜åŒ–å™¨ - ä¼˜åŒ–æŠ¥å‘Š

## ğŸ“Š ä¼˜åŒ–ç»Ÿè®¡

- **æ€»ä¼˜åŒ–æ¬¡æ•°**: {stats.get('total_optimizations', 0)}
- **æˆåŠŸä¼˜åŒ–æ¬¡æ•°**: {stats.get('successful_optimizations', 0)}
- **æˆåŠŸç‡**: {stats.get('success_rate', 0.0):.1%}
- **å¹³å‡æ”¹è¿›å¹…åº¦**: {stats.get('average_improvement', 0.0):.1f}åˆ†
- **æ”¹è¿›æ ‡å‡†å·®**: {stats.get('improvement_std', 0.0):.2f}
- **æ”¹è¿›èŒƒå›´**: {stats.get('improvement_range', (0, 0))}
- **å¹³å‡è¿­ä»£æ¬¡æ•°**: {stats.get('average_iterations', 0.0):.1f}
- **å¹³å‡ä¼˜åŒ–æ—¶é—´**: {stats.get('average_time', 0.0):.3f}ç§’

## ğŸ“ˆ ç­–ç•¥æ•ˆæœåˆ†æ

"""
        
        # ç­–ç•¥ç»Ÿè®¡
        strategy_stats = stats.get('strategy_statistics', {})
        for strategy, stat in sorted(strategy_stats.items(), key=lambda x: x[1]['average_improvement'], reverse=True):
            report_content += f"""
### {strategy.replace('_', ' ').title()}

- **ä½¿ç”¨æ¬¡æ•°**: {stat['usage_count']}
- **å¹³å‡æ”¹è¿›**: {stat['average_improvement']:.1f}åˆ†
- **æˆåŠŸç‡**: {stat['success_rate']:.1%}
"""
        
        # æ‰¹é‡ä¼˜åŒ–ç»“æœ
        if batch_result:
            report_content += f"""

## ğŸ¯ æ‰¹é‡ä¼˜åŒ–ç»“æœ

- **å¤„ç†æ–‡æœ¬æ•°**: {batch_result.total_texts}
- **æˆåŠŸä¼˜åŒ–æ•°**: {batch_result.successful_optimizations}
- **å¹³å‡æ”¹è¿›**: {batch_result.average_improvement:.1f}åˆ†
- **æ€»å¤„ç†æ—¶é—´**: {batch_result.processing_statistics['total_time']:.1f}ç§’
- **å¹³å‡æ¯æ–‡æœ¬æ—¶é—´**: {batch_result.processing_statistics['average_time_per_text']:.3f}ç§’

### ğŸ“Š ç­–ç•¥æ•ˆæœæ’å

"""
            for strategy, effectiveness in sorted(batch_result.strategy_effectiveness.items(), key=lambda x: x[1], reverse=True):
                report_content += f"- **{strategy.replace('_', ' ').title()}**: {effectiveness:.1f}åˆ†å¹³å‡æ”¹è¿›\n"
        
        # æœ€è¿‘ä¼˜åŒ–ç¤ºä¾‹
        if self.optimization_history:
            report_content += f"""

## ğŸ“ æœ€è¿‘ä¼˜åŒ–ç¤ºä¾‹

"""
            for i, session in enumerate(self.optimization_history[-3:], 1):
                report_content += f"""
### ç¤ºä¾‹ {i}

**åŸå§‹æ–‡æœ¬**: {session.original_text[:100]}{'...' if len(session.original_text) > 100 else ''}

**æœ€ç»ˆæ–‡æœ¬**: {session.final_text[:100]}{'...' if len(session.final_text) > 100 else ''}

**ä¼˜åŒ–æ•ˆæœ**: {session.initial_score:.1f} â†’ {session.final_score:.1f} (æ”¹è¿›: {session.total_improvement:+.1f})

**è¿­ä»£æ¬¡æ•°**: {session.iterations_used}

**ç»“æœçŠ¶æ€**: {session.result_status.value}

**ä½¿ç”¨ç­–ç•¥**: {', '.join([s.value for s in session.strategies_used])}

"""
        
        report_content += f"""

## ğŸ”§ ä¼˜åŒ–é…ç½®

### é»˜è®¤å‚æ•°
- ç›®æ ‡è¯„åˆ†: {self.config.target_score}
- æœ€å¤§è¿­ä»£æ¬¡æ•°: {self.config.max_iterations}
- æ”¹è¿›é˜ˆå€¼: {self.config.improvement_threshold}
- æ”¶æ•›é˜ˆå€¼: {self.config.convergence_threshold}
- ä¿æŒè¯­ä¹‰: {self.config.preserve_meaning}

### ä¼˜åŒ–ç­–ç•¥
- è¯æ±‡å¢å¼º: å¤å…¸è¯æ±‡æ›¿æ¢ï¼Œç°ä»£è¯æ±‡æ¶ˆé™¤
- å¥å¼é‡æ„: å¢åŠ å¥å­é•¿åº¦å’Œå¤æ‚åº¦ï¼Œå¤å…¸å¥å¼æ¨¡å¼
- ä¿®è¾æ”¹è¿›: æ·»åŠ æ¯”å–»ã€å¯¹å¶ç­‰ä¿®è¾æ‰‹æ³•
- ç§°è°“çº æ­£: ç¡®ä¿ç§°è°“çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§
- ç»¼åˆä¼˜åŒ–: å¤šç»´åº¦åŒæ—¶ä¼˜åŒ–

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        try:
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            self.logger.info(f"ä¼˜åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {file_path}")
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Šå¤±è´¥: {e}")


def create_realtime_style_optimizer(converter: Optional[IntelligentStyleConverter] = None,
                                   evaluator: Optional[StyleSimilarityEvaluator] = None,
                                   config: Optional[OptimizationConfig] = None) -> RealtimeStyleOptimizer:
    """åˆ›å»ºå®æ—¶æ–‡é£ä¼˜åŒ–å™¨å®ä¾‹"""
    return RealtimeStyleOptimizer(converter, evaluator, config) 